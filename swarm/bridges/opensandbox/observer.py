"""Observability and measurement layer for the OpenSandbox bridge.

Spans all layers.  Collects execution logs, governance events,
message traces, and agent behavioral metrics.  Feeds data into
safety analysis pipelines for measuring sorting effects, detecting
emergent risks, and validating constitutional AI adaptations.
"""

import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

from swarm.bridges.opensandbox.events import OpenSandboxEvent, OpenSandboxEventType

logger = logging.getLogger(__name__)


@dataclass
class AgentMetrics:
    """Behavioral metrics for a single agent.

    Attributes:
        agent_id: Agent identifier.
        contract_id: Assigned contract.
        tier: Contract tier.
        total_commands: Total commands executed.
        successful_commands: Commands with exit_code 0.
        violations: Contract violations detected.
        interventions: Governance interventions applied.
        total_messages: Messages sent.
        delivered_messages: Messages successfully delivered.
        blocked_messages: Messages blocked by policy.
        avg_p: Running average of interaction p values.
        risk_score: Current risk score [0, 1].
    """

    agent_id: str = ""
    contract_id: str = ""
    tier: str = ""
    total_commands: int = 0
    successful_commands: int = 0
    violations: int = 0
    interventions: int = 0
    total_messages: int = 0
    delivered_messages: int = 0
    blocked_messages: int = 0
    avg_p: float = 0.5
    risk_score: float = 0.0
    _p_sum: float = 0.0
    _p_count: int = 0

    def record_p(self, p: float) -> None:
        """Update the running average of p."""
        self._p_sum += p
        self._p_count += 1
        self.avg_p = self._p_sum / self._p_count

    def to_dict(self) -> Dict[str, Any]:
        """Serialize for reporting."""
        return {
            "agent_id": self.agent_id,
            "contract_id": self.contract_id,
            "tier": self.tier,
            "total_commands": self.total_commands,
            "successful_commands": self.successful_commands,
            "violations": self.violations,
            "interventions": self.interventions,
            "total_messages": self.total_messages,
            "delivered_messages": self.delivered_messages,
            "blocked_messages": self.blocked_messages,
            "avg_p": round(self.avg_p, 4),
            "risk_score": round(self.risk_score, 4),
        }

    def to_stats_dict(self) -> Dict[str, int]:
        """Return integer stats for the mapper."""
        return {
            "total_commands": self.total_commands,
            "successful_commands": self.successful_commands,
            "violations": self.violations,
            "interventions": self.interventions,
            "total_messages": self.total_messages,
            "delivered_messages": self.delivered_messages,
            "blocked_messages": self.blocked_messages,
        }


@dataclass
class ExperimentMetrics:
    """Aggregate metrics for a full experiment run.

    Attributes:
        experiment_id: Experiment identifier.
        sorting_coefficient: How strongly agent types correlate with
            assigned tiers (higher = more self-sorting).
        intervention_rate: Fraction of agents that received at least
            one governance intervention.
        constitutional_adherence: Fraction of actions that passed
            all safety invariant checks.
        emergent_risk_frequency: Number of emergent risk alerts
            per agent-hour.
        avg_p_by_tier: Average p by contract tier.
        agent_count_by_tier: Agent count by contract tier.
    """

    experiment_id: str = ""
    sorting_coefficient: float = 0.0
    intervention_rate: float = 0.0
    constitutional_adherence: float = 1.0
    emergent_risk_frequency: float = 0.0
    avg_p_by_tier: Dict[str, float] = field(default_factory=dict)
    agent_count_by_tier: Dict[str, int] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Serialize for reporting."""
        return {
            "experiment_id": self.experiment_id,
            "sorting_coefficient": round(self.sorting_coefficient, 4),
            "intervention_rate": round(self.intervention_rate, 4),
            "constitutional_adherence": round(self.constitutional_adherence, 4),
            "emergent_risk_frequency": round(self.emergent_risk_frequency, 4),
            "avg_p_by_tier": {
                k: round(v, 4) for k, v in self.avg_p_by_tier.items()
            },
            "agent_count_by_tier": dict(self.agent_count_by_tier),
        }


class Observer:
    """Observability layer for the OpenSandbox bridge.

    Aggregates signals from all bridge subsystems into per-agent
    and per-experiment metrics.  Detects emergent risk patterns
    and triggers governance alerts.

    Example::

        observer = Observer(risk_threshold=0.7)
        observer.register_agent("agent-a", "restricted-v1", "restricted")
        observer.record_command("agent-a", success=True)
        observer.record_message("agent-a", delivered=True)
        alert = observer.check_risk("agent-a")
        metrics = observer.compute_experiment_metrics("exp-001")
    """

    def __init__(self, risk_threshold: float = 0.7) -> None:
        self._risk_threshold = risk_threshold
        self._agents: Dict[str, AgentMetrics] = {}
        self._events: List[OpenSandboxEvent] = []
        self._risk_alerts: List[Dict[str, Any]] = []

    # ------------------------------------------------------------------
    # Registration
    # ------------------------------------------------------------------

    def register_agent(
        self,
        agent_id: str,
        contract_id: str = "",
        tier: str = "",
    ) -> None:
        """Register an agent for tracking."""
        self._agents[agent_id] = AgentMetrics(
            agent_id=agent_id,
            contract_id=contract_id,
            tier=tier,
        )

    def unregister_agent(self, agent_id: str) -> None:
        """Remove an agent from tracking."""
        self._agents.pop(agent_id, None)

    # ------------------------------------------------------------------
    # Recording
    # ------------------------------------------------------------------

    def record_command(self, agent_id: str, success: bool) -> None:
        """Record a command execution."""
        metrics = self._agents.get(agent_id)
        if metrics is None:
            return
        metrics.total_commands += 1
        if success:
            metrics.successful_commands += 1

    def record_violation(self, agent_id: str) -> None:
        """Record a contract violation."""
        metrics = self._agents.get(agent_id)
        if metrics is None:
            return
        metrics.violations += 1
        self._update_risk(agent_id)

    def record_intervention(self, agent_id: str) -> None:
        """Record a governance intervention."""
        metrics = self._agents.get(agent_id)
        if metrics is None:
            return
        metrics.interventions += 1
        self._update_risk(agent_id)

    def record_message(self, agent_id: str, delivered: bool) -> None:
        """Record a message sent by the agent."""
        metrics = self._agents.get(agent_id)
        if metrics is None:
            return
        metrics.total_messages += 1
        if delivered:
            metrics.delivered_messages += 1
        else:
            metrics.blocked_messages += 1

    def record_p(self, agent_id: str, p: float) -> None:
        """Record a p value from a SoftInteraction."""
        metrics = self._agents.get(agent_id)
        if metrics is None:
            return
        metrics.record_p(p)
        self._update_risk(agent_id)

    # ------------------------------------------------------------------
    # Risk detection
    # ------------------------------------------------------------------

    def check_risk(self, agent_id: str) -> Optional[Dict[str, Any]]:
        """Check if an agent exceeds the risk threshold.

        Returns:
            A risk alert dict if threshold exceeded, else None.
        """
        metrics = self._agents.get(agent_id)
        if metrics is None:
            return None

        if metrics.risk_score >= self._risk_threshold:
            alert = {
                "agent_id": agent_id,
                "risk_score": metrics.risk_score,
                "violations": metrics.violations,
                "interventions": metrics.interventions,
                "avg_p": metrics.avg_p,
            }
            self._risk_alerts.append(alert)
            self._events.append(
                OpenSandboxEvent(
                    event_type=OpenSandboxEventType.RISK_ALERT,
                    agent_id=agent_id,
                    payload=alert,
                )
            )
            logger.warning(
                "Risk alert for agent %s: score=%.3f",
                agent_id,
                metrics.risk_score,
            )
            return alert
        return None

    # ------------------------------------------------------------------
    # Experiment metrics
    # ------------------------------------------------------------------

    def compute_experiment_metrics(
        self,
        experiment_id: str,
    ) -> ExperimentMetrics:
        """Compute aggregate experiment metrics.

        Measures:
        - sorting_coefficient: variance of avg_p across tiers
          (higher variance → stronger self-sorting).
        - intervention_rate: fraction of agents intervened upon.
        - constitutional_adherence: 1 - (violations / total_actions).
        - emergent_risk_frequency: risk alerts per agent.

        Args:
            experiment_id: Experiment identifier.

        Returns:
            ExperimentMetrics with computed values.
        """
        if not self._agents:
            return ExperimentMetrics(experiment_id=experiment_id)

        # Group by tier
        tier_p_sums: Dict[str, float] = {}
        tier_counts: Dict[str, int] = {}
        total_violations = 0
        total_actions = 0
        agents_intervened = 0

        for m in self._agents.values():
            tier_p_sums[m.tier] = tier_p_sums.get(m.tier, 0.0) + m.avg_p
            tier_counts[m.tier] = tier_counts.get(m.tier, 0) + 1
            total_violations += m.violations
            total_actions += m.total_commands + m.total_messages
            if m.interventions > 0:
                agents_intervened += 1

        n_agents = len(self._agents)
        avg_p_by_tier = {
            tier: tier_p_sums[tier] / tier_counts[tier]
            for tier in tier_counts
        }

        # Sorting coefficient: std dev of tier average p's
        if len(avg_p_by_tier) > 1:
            mean_p = sum(avg_p_by_tier.values()) / len(avg_p_by_tier)
            variance = sum(
                (v - mean_p) ** 2 for v in avg_p_by_tier.values()
            ) / len(avg_p_by_tier)
            sorting_coeff = variance ** 0.5
        else:
            sorting_coeff = 0.0

        intervention_rate = agents_intervened / max(n_agents, 1)
        adherence = 1.0 - (total_violations / max(total_actions, 1))
        risk_freq = len(self._risk_alerts) / max(n_agents, 1)

        result = ExperimentMetrics(
            experiment_id=experiment_id,
            sorting_coefficient=sorting_coeff,
            intervention_rate=intervention_rate,
            constitutional_adherence=max(0.0, adherence),
            emergent_risk_frequency=risk_freq,
            avg_p_by_tier=avg_p_by_tier,
            agent_count_by_tier=dict(tier_counts),
        )

        self._events.append(
            OpenSandboxEvent(
                event_type=OpenSandboxEventType.METRICS_COMPUTED,
                payload=result.to_dict(),
            )
        )

        return result

    # ------------------------------------------------------------------
    # Accessors
    # ------------------------------------------------------------------

    def get_agent_metrics(self, agent_id: str) -> Optional[AgentMetrics]:
        """Return metrics for a specific agent."""
        return self._agents.get(agent_id)

    def get_all_agent_metrics(self) -> Dict[str, AgentMetrics]:
        """Return metrics for all agents."""
        return dict(self._agents)

    def get_risk_alerts(self) -> List[Dict[str, Any]]:
        """Return all risk alerts."""
        return list(self._risk_alerts)

    def get_events(self) -> List[OpenSandboxEvent]:
        """Return all observer events."""
        return list(self._events)

    # ------------------------------------------------------------------
    # Internal
    # ------------------------------------------------------------------

    def _update_risk(self, agent_id: str) -> None:
        """Recompute risk score for an agent.

        Risk factors:
        - Low avg_p (inverted: lower p → higher risk)
        - High violation rate
        - History of interventions
        """
        metrics = self._agents.get(agent_id)
        if metrics is None:
            return

        p_risk = 1.0 - metrics.avg_p  # [0, 1]

        total = max(metrics.total_commands + metrics.total_messages, 1)
        violation_rate = min(1.0, metrics.violations / total)

        intervention_factor = min(1.0, metrics.interventions * 0.25)

        # Weighted combination
        metrics.risk_score = (
            0.4 * p_risk
            + 0.35 * violation_rate
            + 0.25 * intervention_factor
        )
