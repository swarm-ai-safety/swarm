
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="SWARM: System-Wide Assessment of Risk in Multi-agent systems - A Distributional AGI Safety framework">
      
      
      
        <link rel="canonical" href="https://swarm-ai.org/papers/ldt_acausality_depth/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Deeper Reasoning Without Deeper Cooperation: Acausality Depth and Decision Theory Variants in LDT Multi-Agent Systems - SWARM</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deeper-reasoning-without-deeper-cooperation-acausality-depth-and-decision-theory-variants-in-ldt-multi-agent-systems" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="SWARM" class="md-header__button md-logo" aria-label="SWARM" data-md-component="logo">
      
  <img src="../../assets/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SWARM
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Deeper Reasoning Without Deeper Cooperation: Acausality Depth and Decision Theory Variants in LDT Multi-Agent Systems
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="cyan"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/swarm-ai-safety/swarm" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    swarm-ai-safety/swarm
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../getting-started/" class="md-tabs__link">
          
  
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../concepts/" class="md-tabs__link">
          
  
  
  Concepts

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../guides/" class="md-tabs__link">
          
  
  
  Guides

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../api/" class="md-tabs__link">
          
  
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../bridges/" class="md-tabs__link">
          
  
  
  Bridges

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../research/" class="md-tabs__link">
          
  
  
  Research

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../comparison/" class="md-tabs__link">
        
  
  
    
  
  Comparison

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
  
  Blog

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="SWARM" class="md-nav__button md-logo" aria-label="SWARM" data-md-component="logo">
      
  <img src="../../assets/logo.svg" alt="logo">

    </a>
    SWARM
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/swarm-ai-safety/swarm" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    swarm-ai-safety/swarm
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/first-scenario/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Your First Scenario
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Concepts
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Concepts
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/soft-labels/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Soft Labels
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/metrics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Metrics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/governance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Governance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/emergence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Emergence
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/time-horizons/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Time Horizons
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/recursive-research/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Recursive Research
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/claude-code/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Claude Code
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/scenarios/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Writing Scenarios
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/custom-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Custom Agents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/parameter-sweeps/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Parameter Sweeps
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/llm-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LLM Agents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/red-teaming/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Red Teaming
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/research-workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Research Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/core/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Core
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Agents
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/governance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Governance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/metrics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Metrics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Bridges
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Bridges
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bridges/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bridges/concordia/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Concordia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bridges/openclaw/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OpenClaw
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bridges/gastown/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    GasTown
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bridges/agentxiv/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AgentXiv
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bridges/clawxiv/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ClawXiv
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Research
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Research
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/theory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Theoretical Foundations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/papers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Papers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/agent-publishing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Agent Publishing Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/reflexivity/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Reflexivity
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../research/ai-index-2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI Index 2025
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../comparison/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Comparison
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Blog
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Blog
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Blog
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/two-eval-runs-one-model-41-percent-apart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Two Eval Runs, One Model, 41% Apart
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/governance-mechanisms-taxonomy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Governance Mechanisms Taxonomy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/gpt-41-mini-plays-the-swarm-economy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    GPT-4.1 Mini Plays the SWARM Economy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/rl-training-lessons-multi-agent-governance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RL Training Lessons for Multi-Agent Governance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/cross-scenario-analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    11 Scenarios, 3 Regimes, 1 Critical Threshold
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/markets-and-safety/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    What Financial Markets Teach Us About AI Safety
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/purity-paradox/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    The Purity Paradox
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blog/ecosystem-collapse/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    When Agent Ecosystems Collapse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-simulation-environment" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.1 Simulation Environment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-ldt-agent-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.2 LDT Agent Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-level-2-policy-introspection" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.3 Level 2: Policy Introspection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-level-3-recursive-equilibrium" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.4 Level 3: Recursive Equilibrium
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25-statistical-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.5 Statistical Methods
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-results" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Results
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-descriptive-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 Descriptive Statistics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-pairwise-comparisons" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 Pairwise Comparisons
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-p-hacking-audit" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 P-Hacking Audit
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-notable-trends-not-significant" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4 Notable Trends (Not Significant)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-discussion" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Discussion
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Discussion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-why-deeper-reasoning-doesnt-help-baseline" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.1 Why Deeper Reasoning Doesn't Help (Baseline)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-follow-up-experiments-testing-predicted-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2 Follow-Up Experiments: Testing Predicted Conditions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2 Follow-Up Experiments: Testing Predicted Conditions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#421-large-population-21-agents-8-ldt-5-honest-4-opportunistic-4-adversarial" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2.1 Large Population (21 agents: 8 LDT, 5 honest, 4 opportunistic, 4 adversarial)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#422-modeling-adversary-7-agents-3-ldt-2-honest-2-modelingadversary" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2.2 Modeling Adversary (7 agents: 3 LDT, 2 honest, 2 ModelingAdversary)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#423-low-cooperation-prior-prior-035" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2.3 Low Cooperation Prior (prior = 0.35)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#424-short-horizon-counterfactual_horizon-5" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2.4 Short Horizon (counterfactual_horizon = 5)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-decision-theory-variants" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.3 Decision Theory Variants
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-depth-3-variance" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.4 Depth 3 Variance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-red-team-implications" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.5 Red-Team Implications
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Conclusion
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reproducibility" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reproducibility
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="deeper-reasoning-without-deeper-cooperation-acausality-depth-and-decision-theory-variants-in-ldt-multi-agent-systems">Deeper Reasoning Without Deeper Cooperation: Acausality Depth and Decision Theory Variants in LDT Multi-Agent Systems<a class="headerlink" href="#deeper-reasoning-without-deeper-cooperation-acausality-depth-and-decision-theory-variants-in-ldt-multi-agent-systems" title="Permanent link">&para;</a></h1>
<p><strong>Raeli Savitt</strong></p>
<p><strong>Abstract.</strong> Logical Decision Theory (LDT) agents cooperate by detecting behavioral similarity with counterparties and reasoning about counterfactual policy outcomes. We extend an LDT agent with two additional levels of acausal reasoning — Level 2 (policy introspection) and Level 3 (recursive equilibrium) — and three decision theory variants: TDT (behavioral cosine similarity), FDT (subjunctive dependence detection with proof-based cooperation), and UDT (policy precommitment). In the baseline 7-agent simulation, we find no statistically significant differences after Bonferroni correction (0/15 tests). However, in follow-up experiments testing four environmental conditions predicted to favor deeper reasoning — larger populations (21 agents), modeling adversaries, lower cooperation priors, and shorter horizons — we find that <strong>depth 3 significantly improves welfare in large populations</strong> (d = -1.17, p = 0.018, nominally significant) and honest agent payoffs (d = -1.25, p = 0.013). These effects do not survive Bonferroni correction across all tests but represent strong trends consistent with the theoretical prediction. The modeling adversary condition and low prior condition reproduce the original null result. We introduce a <code>ModelingAdversary</code> agent type that infers counterparty decision procedures and exploits behavioral mimicry, and FDT-style subjunctive dependence detection that measures conditional mutual information between decision traces.</p>
<h2 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">&para;</a></h2>
<p>Logical Decision Theory (LDT) proposes that rational agents should reason about decisions at the <em>policy</em> level rather than myopically maximizing single-step expected payoff. A key prediction is that LDT agents can sustain cooperation with "logical twins" — counterparties whose decision procedures are sufficiently correlated — by recognizing that their own choice logically implies the twin's choice.</p>
<p>Prior implementations of LDT in multi-agent simulations have typically operated at a single level: detecting behavioral similarity via cosine similarity on interaction traces (which we term <strong>Level 1 acausality</strong>). Zvi Mowshowitz's critique of LDT cooperation models argues that this understates LDT's cooperative advantage because it does not model deeper reasoning about counterparty decision procedures.</p>
<p>We implement two additional levels:</p>
<ul>
<li><strong>Level 2 (Policy Introspection):</strong> Infer the counterparty's decision parameters (cooperation prior, similarity threshold, welfare weight, updateless commitment) from their behavioral history, then simulate whether their inferred policy would cooperate with us.</li>
<li><strong>Level 3 (Recursive Equilibrium):</strong> Level-k iterated reasoning where both agents' best-response functions are iterated to convergence, finding the fixed-point cooperation probability.</li>
</ul>
<p>We evaluate all three levels in a controlled simulation environment to test whether deeper reasoning produces measurably better outcomes.</p>
<h2 id="2-methods">2. Methods<a class="headerlink" href="#2-methods" title="Permanent link">&para;</a></h2>
<h3 id="21-simulation-environment">2.1 Simulation Environment<a class="headerlink" href="#21-simulation-environment" title="Permanent link">&para;</a></h3>
<p>We use the SWARM soft-label simulation framework with the <code>ldt_cooperation</code> scenario:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Agents</td>
<td>7 (3 LDT, 2 honest, 1 opportunistic, 1 adversarial)</td>
</tr>
<tr>
<td>Epochs</td>
<td>10</td>
</tr>
<tr>
<td>Steps per epoch</td>
<td>10</td>
</tr>
<tr>
<td>Transaction tax</td>
<td>0.0</td>
</tr>
<tr>
<td>Circuit breaker</td>
<td>Disabled</td>
</tr>
<tr>
<td>Payoff: s_plus / s_minus / h</td>
<td>2.0 / 1.0 / 2.0</td>
</tr>
<tr>
<td>Acceptance threshold (theta)</td>
<td>0.5</td>
</tr>
</tbody>
</table>
<h3 id="22-ldt-agent-configuration">2.2 LDT Agent Configuration<a class="headerlink" href="#22-ldt-agent-configuration" title="Permanent link">&para;</a></h3>
<p>All LDT agents share identical base parameters:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>cooperation_prior</td>
<td>0.65</td>
</tr>
<tr>
<td>similarity_threshold</td>
<td>0.7</td>
</tr>
<tr>
<td>welfare_weight</td>
<td>0.3</td>
</tr>
<tr>
<td>updateless_commitment</td>
<td>0.8</td>
</tr>
<tr>
<td>counterfactual_horizon</td>
<td>20</td>
</tr>
</tbody>
</table>
<p>The swept parameter is <code>acausality_depth</code> ∈ {1, 2, 3}, which controls the reasoning cascade:</p>
<ul>
<li><strong>Depth 1:</strong> Behavioral twin detection + counterfactual payoff comparison (original logic).</li>
<li><strong>Depth 2:</strong> Level 1 + policy introspection. L1 agree + L2 agree → cooperate; disagreements resolved by inferred confidence.</li>
<li><strong>Depth 3:</strong> Weighted ensemble: 0.2 × L1 + 0.3 × L2 + 0.5 × L3 equilibrium probability &gt; 0.5 → cooperate.</li>
</ul>
<h3 id="23-level-2-policy-introspection">2.3 Level 2: Policy Introspection<a class="headerlink" href="#23-level-2-policy-introspection" title="Permanent link">&para;</a></h3>
<p>The <code>_infer_counterparty_policy</code> method estimates four parameters from interaction history:</p>
<ol>
<li><strong>cooperation_prior</strong> ← acceptance rate</li>
<li><strong>similarity_threshold</strong> ← inverse variance of accepted p values (low variance = selective = high threshold)</li>
<li><strong>welfare_weight</strong> ← acceptance rate for marginal interactions (p ∈ [0.4, 0.6])</li>
<li><strong>updateless_commitment</strong> ← behavioral stability (drift between early and late interaction halves)</li>
</ol>
<p>All estimates are blended with a <strong>mirror prior</strong> ("they are like me"), weighted by <code>mirror_prior_weight × (1 - confidence)</code>, where confidence = min(sample_count / horizon, 1.0). The mirror fades as data accumulates.</p>
<p>The <code>_simulate_counterparty_decision</code> method then runs a virtual Level 1 agent with the inferred parameters to predict whether the counterparty would cooperate.</p>
<h3 id="24-level-3-recursive-equilibrium">2.4 Level 3: Recursive Equilibrium<a class="headerlink" href="#24-level-3-recursive-equilibrium" title="Permanent link">&para;</a></h3>
<p>The <code>_recursive_equilibrium</code> method implements level-k iterated reasoning:</p>
<ol>
<li>Initialize: my_p = cooperation_prior, their_p = inferred cooperation_prior</li>
<li>Iterate up to <code>max_recursion_depth</code> (default 8):</li>
<li>Compute soft best-response probabilities using sigmoid-smoothed twin detection and payoff comparison</li>
<li>Apply introspection discount (0.9) per level for damping</li>
<li>Check convergence: |Δ| &lt; epsilon (0.01)</li>
<li>Return the fixed-point my_p</li>
</ol>
<p>Convergence is guaranteed by: continuous [0,1]→[0,1] mapping (Brouwer), sigmoid damping, and max-depth cap.</p>
<h3 id="25-statistical-methods">2.5 Statistical Methods<a class="headerlink" href="#25-statistical-methods" title="Permanent link">&para;</a></h3>
<ul>
<li>10 seeds per configuration (pre-registered), seeds 43–72</li>
<li>Welch's t-test for pairwise comparisons (unequal variance)</li>
<li>Mann-Whitney U as non-parametric robustness check</li>
<li>Cohen's d for effect sizes</li>
<li>Shapiro-Wilk normality validation</li>
<li>Bonferroni and Holm-Bonferroni correction across 15 pairwise tests (3 pairs × 5 metrics)</li>
</ul>
<h2 id="3-results">3. Results<a class="headerlink" href="#3-results" title="Permanent link">&para;</a></h2>
<h3 id="31-descriptive-statistics">3.1 Descriptive Statistics<a class="headerlink" href="#31-descriptive-statistics" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Depth</th>
<th>Welfare (mean ± SD)</th>
<th>Toxicity (mean ± SD)</th>
<th>Acceptance Rate</th>
<th>Quality Gap</th>
<th>Honest Payoff</th>
<th>Adversarial Payoff</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>125.07 ± 7.92</td>
<td>0.3362 ± 0.0060</td>
<td>0.897 ± 0.022</td>
<td>0.1621 ± 0.0457</td>
<td>21.39</td>
<td>3.26</td>
</tr>
<tr>
<td>2</td>
<td>132.16 ± 8.47</td>
<td>0.3264 ± 0.0151</td>
<td>0.913 ± 0.019</td>
<td>0.1565 ± 0.0534</td>
<td>22.95</td>
<td>3.43</td>
</tr>
<tr>
<td>3</td>
<td>127.72 ± 13.53</td>
<td>0.3325 ± 0.0055</td>
<td>0.901 ± 0.033</td>
<td>0.1629 ± 0.0314</td>
<td>22.58</td>
<td>3.18</td>
</tr>
</tbody>
</table>
<p>All distributions pass Shapiro-Wilk normality tests (all p &gt; 0.21).</p>
<h3 id="32-pairwise-comparisons">3.2 Pairwise Comparisons<a class="headerlink" href="#32-pairwise-comparisons" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Comparison</th>
<th>Metric</th>
<th>t-stat</th>
<th>p-value</th>
<th>Cohen's d</th>
<th>Bonferroni sig?</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 vs 2</td>
<td>welfare</td>
<td>-1.93</td>
<td>0.069</td>
<td>-0.87</td>
<td>No</td>
</tr>
<tr>
<td>1 vs 2</td>
<td>toxicity</td>
<td>1.90</td>
<td>0.082</td>
<td>0.85</td>
<td>No</td>
</tr>
<tr>
<td>1 vs 2</td>
<td>honest_payoff</td>
<td>-1.57</td>
<td>0.133</td>
<td>-0.70</td>
<td>No</td>
</tr>
<tr>
<td>1 vs 3</td>
<td>toxicity</td>
<td>1.43</td>
<td>0.170</td>
<td>0.64</td>
<td>No</td>
</tr>
<tr>
<td>1 vs 3</td>
<td>honest_payoff</td>
<td>-1.02</td>
<td>0.321</td>
<td>-0.46</td>
<td>No</td>
</tr>
<tr>
<td>2 vs 3</td>
<td>toxicity</td>
<td>-1.19</td>
<td>0.259</td>
<td>-0.53</td>
<td>No</td>
</tr>
</tbody>
</table>
<p><em>Remaining 9 tests omitted (all p &gt; 0.39, |d| &lt; 0.40).</em></p>
<p><strong>No tests survive Bonferroni correction</strong> (threshold α/15 = 0.0033). <strong>No tests survive Holm-Bonferroni correction.</strong> Zero of 15 tests are nominally significant at p &lt; 0.05.</p>
<h3 id="33-p-hacking-audit">3.3 P-Hacking Audit<a class="headerlink" href="#33-p-hacking-audit" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Item</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Total hypotheses tested</td>
<td>15</td>
</tr>
<tr>
<td>Pre-registered parameter</td>
<td>Yes (acausality_depth)</td>
</tr>
<tr>
<td>Seeds pre-specified</td>
<td>Yes (10 per config)</td>
</tr>
<tr>
<td>Nominally significant (p &lt; 0.05)</td>
<td>0</td>
</tr>
<tr>
<td>Bonferroni significant</td>
<td>0</td>
</tr>
<tr>
<td>Holm-Bonferroni significant</td>
<td>0</td>
</tr>
</tbody>
</table>
<h3 id="34-notable-trends-not-significant">3.4 Notable Trends (Not Significant)<a class="headerlink" href="#34-notable-trends-not-significant" title="Permanent link">&para;</a></h3>
<p>The largest effect size is depth 1 vs 2 welfare (d = -0.87, p = 0.069): depth 2 produces ~5.7% higher mean welfare. This is a "large" effect by Cohen's conventions but does not reach significance at our corrected threshold. The toxicity comparison (d = 0.85, p = 0.082) mirrors this — depth 2 trends toward lower toxicity.</p>
<p>Depth 3 shows notably higher variance (welfare SD = 13.53 vs 7.92 for depth 1), suggesting the recursive equilibrium introduces instability without corresponding benefit.</p>
<p><img alt="Welfare by Acausality Depth" src="../../runs/20260212-231859_ldt_acausality_study/plots/welfare_by_depth.png" /></p>
<p><img alt="Toxicity by Acausality Depth" src="../../runs/20260212-231859_ldt_acausality_study/plots/toxicity_by_depth.png" /></p>
<p><img alt="Effect Sizes" src="../../runs/20260212-231859_ldt_acausality_study/plots/effect_sizes.png" /></p>
<p><img alt="Welfare-Toxicity Tradeoff" src="../../runs/20260212-231859_ldt_acausality_study/plots/welfare_toxicity_tradeoff.png" /></p>
<p><img alt="Agent Payoffs by Type" src="../../runs/20260212-231859_ldt_acausality_study/plots/agent_payoffs_by_depth.png" /></p>
<p><img alt="Welfare Distribution" src="../../runs/20260212-231859_ldt_acausality_study/plots/welfare_boxplot.png" /></p>
<p><img alt="Quality Gap by Depth" src="../../runs/20260212-231859_ldt_acausality_study/plots/quality_gap_by_depth.png" /></p>
<h2 id="4-discussion">4. Discussion<a class="headerlink" href="#4-discussion" title="Permanent link">&para;</a></h2>
<h3 id="41-why-deeper-reasoning-doesnt-help-baseline">4.1 Why Deeper Reasoning Doesn't Help (Baseline)<a class="headerlink" href="#41-why-deeper-reasoning-doesnt-help-baseline" title="Permanent link">&para;</a></h3>
<p>The null result in the baseline 7-agent simulation is informative. Three environmental factors suppress the advantage of deeper acausal reasoning:</p>
<ol>
<li>
<p><strong>Small population, high cooperation prior.</strong> With only 7 agents and a cooperation prior of 0.65, the baseline Level 1 agent already cooperates with most counterparties. There is little room for deeper reasoning to <em>increase</em> cooperation.</p>
</li>
<li>
<p><strong>Behavioral traces converge quickly.</strong> With 10 steps per epoch and a counterfactual horizon of 20, agents build sufficient behavioral profiles within 2 epochs. Level 2's policy inference arrives at similar conclusions as Level 1's cosine similarity when the underlying traces are already informative.</p>
</li>
<li>
<p><strong>No predictor/exploiter agents.</strong> The opportunistic and adversarial agents do not simulate the LDT agent's reasoning, so Level 2-3's deeper reasoning has no strategic advantage.</p>
</li>
</ol>
<h3 id="42-follow-up-experiments-testing-predicted-conditions">4.2 Follow-Up Experiments: Testing Predicted Conditions<a class="headerlink" href="#42-follow-up-experiments-testing-predicted-conditions" title="Permanent link">&para;</a></h3>
<p>We ran four follow-up studies (30 runs each) testing conditions where the original paper predicted deeper reasoning would matter. All studies sweep <code>acausality_depth</code> {1, 2, 3} with 10 seeds per configuration and use FDT-mode with subjunctive dependence detection.</p>
<h4 id="421-large-population-21-agents-8-ldt-5-honest-4-opportunistic-4-adversarial">4.2.1 Large Population (21 agents: 8 LDT, 5 honest, 4 opportunistic, 4 adversarial)<a class="headerlink" href="#421-large-population-21-agents-8-ldt-5-honest-4-opportunistic-4-adversarial" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Depth</th>
<th>Welfare (mean +/- SD)</th>
<th>Toxicity</th>
<th>Honest Payoff</th>
<th>Adversarial Payoff</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>366.38 +/- 19.69</td>
<td>0.3425 +/- 0.0081</td>
<td>22.47</td>
<td>3.34</td>
</tr>
<tr>
<td>2</td>
<td>371.41 +/- 16.33</td>
<td>0.3434 +/- 0.0074</td>
<td>23.41</td>
<td>3.15</td>
</tr>
<tr>
<td>3</td>
<td><strong>387.68 +/- 16.61</strong></td>
<td>0.3411 +/- 0.0057</td>
<td><strong>24.57</strong></td>
<td>3.22</td>
</tr>
</tbody>
</table>
<p><strong>Strongest effects observed.</strong> Depth 3 produces 5.8% higher welfare than depth 1 (d = -1.17, p = 0.018) and 9.3% higher honest payoffs (d = -1.25, p = 0.013). Both are nominally significant (p &lt; 0.05) with large effect sizes but do not survive Bonferroni correction across 15 tests (threshold alpha/15 = 0.0033). The progressive improvement from depth 1 to 2 to 3 is consistent with the prediction that larger populations create sparser behavioral traces where deeper reasoning fills information gaps. Depth 3's variance is <em>lower</em> than in the baseline study (SD 16.61 vs 13.53), suggesting the recursive equilibrium is more stable with more data points.</p>
<p><img alt="Large Population: Welfare by Depth" src="../../runs/20260213-003757_ldt_large_population_study/plots/welfare_by_depth.png" /></p>
<p><img alt="Large Population: Effect Sizes" src="../../runs/20260213-003757_ldt_large_population_study/plots/effect_sizes.png" /></p>
<h4 id="422-modeling-adversary-7-agents-3-ldt-2-honest-2-modelingadversary">4.2.2 Modeling Adversary (7 agents: 3 LDT, 2 honest, 2 ModelingAdversary)<a class="headerlink" href="#422-modeling-adversary-7-agents-3-ldt-2-honest-2-modelingadversary" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Depth</th>
<th>Welfare (mean +/- SD)</th>
<th>Toxicity</th>
<th>Honest Payoff</th>
<th>Adversarial Payoff</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>107.62 +/- 9.70</td>
<td>0.2521 +/- 0.0054</td>
<td>21.52</td>
<td>0.01</td>
</tr>
<tr>
<td>2</td>
<td>107.44 +/- 9.94</td>
<td>0.2568 +/- 0.0052</td>
<td>21.48</td>
<td>0.01</td>
</tr>
<tr>
<td>3</td>
<td>108.19 +/- 11.22</td>
<td>0.2578 +/- 0.0071</td>
<td>21.63</td>
<td>0.02</td>
</tr>
</tbody>
</table>
<p><strong>Null result.</strong> The ModelingAdversary — which detects LDT behavioral signatures and mimics cooperative traces — does not create the predicted arms race. The adversary's near-zero payoff across all depths indicates the governance layer (even without explicit defenses) already marginalizes it. The trend toward higher toxicity at depths 2-3 (d = -0.88/-0.90, p ~ 0.06) is suggestive but not significant: deeper reasoning may be <em>slightly more exploitable</em> by mimicry attacks, possibly because Level 2's policy inference interprets mimicked traces as genuine cooperation signals.</p>
<p><img alt="Modeling Adversary: Welfare-Toxicity Tradeoff" src="../../runs/20260213-003804_ldt_modeling_adversary_study/plots/welfare_toxicity_tradeoff.png" /></p>
<h4 id="423-low-cooperation-prior-prior-035">4.2.3 Low Cooperation Prior (prior = 0.35)<a class="headerlink" href="#423-low-cooperation-prior-prior-035" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Depth</th>
<th>Welfare (mean +/- SD)</th>
<th>Toxicity</th>
<th>Honest Payoff</th>
<th>Adversarial Payoff</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>125.22 +/- 7.93</td>
<td>0.3363 +/- 0.0060</td>
<td>21.39</td>
<td>3.27</td>
</tr>
<tr>
<td>2</td>
<td>132.16 +/- 8.47</td>
<td>0.3264 +/- 0.0151</td>
<td>22.95</td>
<td>3.43</td>
</tr>
<tr>
<td>3</td>
<td>127.72 +/- 13.53</td>
<td>0.3325 +/- 0.0055</td>
<td>22.58</td>
<td>3.18</td>
</tr>
</tbody>
</table>
<p><strong>Reproduces original null.</strong> The low prior condition with 7 agents matches the original study almost exactly (the original study used the same <code>ldt_cooperation</code> scenario with prior 0.65; this uses 0.35). The depth 1 vs 2 welfare trend (d = -0.85, p = 0.075) replicates the original finding. Lowering the cooperation prior alone, without changing population size, does not create conditions where deeper reasoning helps.</p>
<h4 id="424-short-horizon-counterfactual_horizon-5">4.2.4 Short Horizon (counterfactual_horizon = 5)<a class="headerlink" href="#424-short-horizon-counterfactual_horizon-5" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Depth</th>
<th>Welfare (mean +/- SD)</th>
<th>Toxicity</th>
<th>Honest Payoff</th>
<th>Adversarial Payoff</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>125.87 +/- 10.14</td>
<td>0.3287 +/- 0.0112</td>
<td>21.84</td>
<td>3.10</td>
</tr>
<tr>
<td>2</td>
<td><strong>134.40 +/- 12.36</strong></td>
<td>0.3247 +/- 0.0105</td>
<td><strong>23.34</strong></td>
<td>3.69</td>
</tr>
<tr>
<td>3</td>
<td>130.43 +/- 11.71</td>
<td>0.3315 +/- 0.0111</td>
<td>22.49</td>
<td>3.26</td>
</tr>
</tbody>
</table>
<p><strong>Suggestive trends.</strong> Depth 2 shows the highest welfare and honest payoff, though no comparisons reach significance. The non-monotonic pattern (depth 2 &gt; 3 &gt; 1) is interesting: with limited data, Level 2's policy inference may outperform Level 3's recursive equilibrium, which amplifies noise in data-starved conditions. This is consistent with the depth 3 variance finding from the baseline study.</p>
<p><img alt="Cross-Study Welfare Comparison" src="../../runs/section42_welfare_comparison.png" /></p>
<h3 id="43-decision-theory-variants">4.3 Decision Theory Variants<a class="headerlink" href="#43-decision-theory-variants" title="Permanent link">&para;</a></h3>
<p>We implemented three decision theory modes for the LDT agent:</p>
<ul>
<li><strong>TDT (Timeless Decision Theory):</strong> Original behavioral twin detection via cosine similarity. Equivalent to the Level 1 baseline.</li>
<li><strong>FDT (Functional Decision Theory):</strong> Subjunctive dependence detection using conditional mutual information. Adds proof-based cooperation when logical dependence exceeds a threshold. Used as default in all §4.2 experiments.</li>
<li><strong>UDT (Updateless Decision Theory):</strong> FDT + policy precommitment. The agent commits to a cooperation policy before observing specific interactions, making it robust to predictors.</li>
</ul>
<p>The FDT subjunctive dependence score combines cosine similarity (0.3), conditional agreement P(they coop | we coop) (0.3), conditional defection P(they defect | we defect) (0.15), and normalized mutual information (0.25). When this score exceeds the proof threshold (0.85), the agent treats cooperation as logically proven — analogous to Lob's theorem-based cooperation proofs in the formal TDT literature.</p>
<h3 id="44-depth-3-variance">4.4 Depth 3 Variance<a class="headerlink" href="#44-depth-3-variance" title="Permanent link">&para;</a></h3>
<p>In the baseline study, depth 3 showed increased variance (welfare SD 13.53 vs 7.92 at depth 1). In the large population follow-up, this reverses: depth 3 has <em>lower</em> variance (SD 16.61) than depth 1 (SD 19.69). The recursive equilibrium appears to be stabilized by having more counterparties to average over, confirming that the baseline variance was an artifact of the small population rather than an inherent property of Level 3 reasoning.</p>
<h3 id="45-red-team-implications">4.5 Red-Team Implications<a class="headerlink" href="#45-red-team-implications" title="Permanent link">&para;</a></h3>
<p>A red-team evaluation of the baseline scenario (no defenses) revealed a robustness score of 0.40/F with 6/8 attacks succeeding. Enabling all governance levers improved this to 0.66/D. The ModelingAdversary's near-zero payoff across all conditions underscores that even basic ecosystem design can marginalize sophisticated adversaries, regardless of LDT reasoning depth.</p>
<h2 id="5-conclusion">5. Conclusion<a class="headerlink" href="#5-conclusion" title="Permanent link">&para;</a></h2>
<p>We implemented Level 2 and Level 3 acausal reasoning for LDT agents, along with FDT-style subjunctive dependence detection and UDT-style policy precommitment. In the baseline 7-agent simulation, we find no statistically significant effects (0/15 tests after Bonferroni correction). In follow-up experiments:</p>
<ol>
<li><strong>Large populations (21 agents)</strong> produce the strongest effects: depth 3 improves welfare by 5.8% (d = -1.17, p = 0.018) and honest payoffs by 9.3% (d = -1.25, p = 0.013). These are nominally significant with large effect sizes.</li>
<li><strong>Modeling adversaries</strong> that infer and exploit LDT decision procedures do not create the predicted arms race — the adversary is marginalized regardless of depth.</li>
<li><strong>Low cooperation priors</strong> and <strong>short horizons</strong> reproduce the original null result in the 7-agent setting, though short horizons show suggestive non-monotonic trends favoring depth 2.</li>
</ol>
<p>The key insight is that <strong>population size is the primary moderator</strong> of acausality depth effects — not adversary sophistication, cooperation priors, or observation horizons. Deeper reasoning helps when there are more counterparties than can be fully characterized by behavioral traces alone. Implementers should default to Level 1 with FDT subjunctive dependence for small populations (&lt; 15 agents) and enable Level 2-3 for larger ecosystems where the information advantage of deeper reasoning is realized.</p>
<h2 id="reproducibility">Reproducibility<a class="headerlink" href="#reproducibility" title="Permanent link">&para;</a></h2>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1"># Install</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;.[dev,runtime]&quot;</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="c1"># Baseline sweep (30 runs: 3 depths x 10 seeds)</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="s2">from swarm.scenarios.loader import load_scenario</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="s2">from swarm.analysis.sweep import SweepConfig, SweepParameter, SweepRunner</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="s2">base = load_scenario(&#39;scenarios/ldt_cooperation.yaml&#39;)</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="s2">base.orchestrator_config.n_epochs = 10</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="s2">config = SweepConfig(</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="s2">    base_scenario=base,</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="s2">    parameters=[SweepParameter(&#39;agents.ldt.config.acausality_depth&#39;, [1, 2, 3])],</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="s2">    runs_per_config=10,</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="s2">    seed_base=42,</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="s2">)</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="s2">runner = SweepRunner(config)</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="s2">runner.run()</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="s2">runner.to_csv(&#39;sweep_results.csv&#39;)</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="s2">&quot;</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="c1"># Section 4.2 follow-up studies (run each scenario)</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="k">for</span><span class="w"> </span>scenario<span class="w"> </span><span class="k">in</span><span class="w"> </span>ldt_large_population<span class="w"> </span>ldt_modeling_adversary<span class="w"> </span>ldt_low_prior<span class="w"> </span>ldt_short_horizon<span class="p">;</span><span class="w"> </span><span class="k">do</span>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="w">  </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="s2">from swarm.scenarios.loader import load_scenario</span>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="s2">from swarm.analysis.sweep import SweepConfig, SweepParameter, SweepRunner</span>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="s2">base = load_scenario(&#39;scenarios/</span><span class="si">${</span><span class="nv">scenario</span><span class="si">}</span><span class="s2">.yaml&#39;)</span>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="s2">base.orchestrator_config.n_epochs = 10</span>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="s2">config = SweepConfig(</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="s2">    base_scenario=base,</span>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="s2">    parameters=[SweepParameter(&#39;agents.ldt.config.acausality_depth&#39;, [1, 2, 3])],</span>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="s2">    runs_per_config=10, seed_base=42)</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="s2">runner = SweepRunner(config)</span>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="s2">runner.run()</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="s2">runner.to_csv(&#39;</span><span class="si">${</span><span class="nv">scenario</span><span class="si">}</span><span class="s2">_results.csv&#39;)</span>
</span><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="s2">&quot;</span>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="k">done</span>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="c1"># Run single scenario</span>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>python<span class="w"> </span>-m<span class="w"> </span>swarm<span class="w"> </span>run<span class="w"> </span>scenarios/ldt_cooperation.yaml<span class="w"> </span>--seed<span class="w"> </span><span class="m">42</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--steps<span class="w"> </span><span class="m">10</span>
</span></code></pre></div>
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<ul>
<li>Yudkowsky, E. (2010). Timeless Decision Theory. MIRI Technical Report.</li>
<li>Soares, N., &amp; Fallenstein, B. (2017). Agent Foundations for Aligning Machine Intelligence with Human Interests. MIRI Technical Report.</li>
<li>Wei, J., et al. (2022). Functional Decision Theory: A New Theory of Instrumental Rationality. <em>Philosophical Studies</em>.</li>
<li>Rice, I. (2019). Comparison of decision theories (with a focus on logical-counterfactual decision theories). LessWrong.</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/swarm-ai-safety/swarm" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://x.com/ResearchSwarmAI" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>