"""Attack scenarios for red-teaming governance.

This module defines a library of attack scenarios that can be used
to test governance robustness.
"""

from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Set
from datetime import datetime


class AttackCategory(Enum):
    """Categories of attacks."""

    EVASION = "evasion"  # Evade detection
    EXPLOITATION = "exploitation"  # Exploit other agents
    MANIPULATION = "manipulation"  # Manipulate system state
    COORDINATION = "coordination"  # Coordinate bad behavior
    RESOURCE = "resource"  # Drain or misallocate resources
    INFORMATION = "information"  # Information manipulation


class AttackDifficulty(Enum):
    """Difficulty level of attacks."""

    TRIVIAL = "trivial"  # Easy to execute
    SIMPLE = "simple"  # Requires basic knowledge
    MODERATE = "moderate"  # Requires some skill
    ADVANCED = "advanced"  # Requires sophisticated strategy
    EXPERT = "expert"  # Requires deep system knowledge


@dataclass
class AttackScenario:
    """Definition of an attack scenario."""

    attack_id: str
    name: str
    description: str
    category: AttackCategory
    difficulty: AttackDifficulty

    # Attack parameters
    n_adversaries: int = 1
    required_epochs: int = 10
    success_condition: str = ""

    # Configuration for adversaries
    adversary_config: Dict[str, Any] = field(default_factory=dict)

    # Expected governance countermeasures
    targeted_levers: List[str] = field(default_factory=list)

    # Metrics to track
    metrics_to_track: List[str] = field(default_factory=list)

    # Setup function (optional)
    setup_fn: Optional[Callable] = None

    def to_dict(self) -> Dict:
        """Serialize to dictionary."""
        return {
            "attack_id": self.attack_id,
            "name": self.name,
            "description": self.description,
            "category": self.category.value,
            "difficulty": self.difficulty.value,
            "n_adversaries": self.n_adversaries,
            "required_epochs": self.required_epochs,
            "success_condition": self.success_condition,
            "targeted_levers": self.targeted_levers,
            "metrics_to_track": self.metrics_to_track,
        }


@dataclass
class AttackResult:
    """Result of running an attack scenario."""

    attack_id: str
    scenario: AttackScenario

    # Timing
    started_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None
    epochs_run: int = 0

    # Outcomes
    attack_succeeded: bool = False
    governance_prevented: bool = False
    detected_at_epoch: Optional[int] = None
    damage_caused: float = 0.0

    # Metrics
    evasion_rate: float = 0.0
    detection_latency: int = 0
    damage_before_detection: float = 0.0
    adversary_payoffs: Dict[str, float] = field(default_factory=dict)
    victim_losses: Dict[str, float] = field(default_factory=dict)

    # Strategy effectiveness
    strategies_used: Dict[str, int] = field(default_factory=dict)
    strategy_success_rates: Dict[str, float] = field(default_factory=dict)

    # Governance response
    penalties_applied: float = 0.0
    agents_frozen: List[str] = field(default_factory=list)
    collusion_detected: bool = False

    def complete(self, success: bool, governance_prevented: bool) -> None:
        """Mark attack as complete."""
        self.completed_at = datetime.now()
        self.attack_succeeded = success
        self.governance_prevented = governance_prevented

    def to_dict(self) -> Dict:
        """Serialize to dictionary."""
        return {
            "attack_id": self.attack_id,
            "scenario": self.scenario.to_dict(),
            "epochs_run": self.epochs_run,
            "attack_succeeded": self.attack_succeeded,
            "governance_prevented": self.governance_prevented,
            "detected_at_epoch": self.detected_at_epoch,
            "damage_caused": self.damage_caused,
            "evasion_rate": self.evasion_rate,
            "detection_latency": self.detection_latency,
            "damage_before_detection": self.damage_before_detection,
            "adversary_payoffs": self.adversary_payoffs,
            "victim_losses": self.victim_losses,
            "strategies_used": self.strategies_used,
            "penalties_applied": self.penalties_applied,
            "agents_frozen": self.agents_frozen,
            "collusion_detected": self.collusion_detected,
        }


class AttackLibrary:
    """Library of predefined attack scenarios."""

    @staticmethod
    def reputation_farming_exploit() -> AttackScenario:
        """
        Attack: Build reputation then exploit trusted relationships.

        Strategy: Act honestly to build reputation, then exploit trust
        for personal gain while maintaining plausible deniability.
        """
        return AttackScenario(
            attack_id="reputation_farming",
            name="Reputation Farming Exploit",
            description=(
                "Build high reputation through honest behavior, then exploit "
                "trusted relationships for personal gain."
            ),
            category=AttackCategory.EXPLOITATION,
            difficulty=AttackDifficulty.MODERATE,
            n_adversaries=1,
            required_epochs=20,
            success_condition="adversary_payoff > 50 AND reputation > 5",
            adversary_config={
                "initial_strategy": "reputation_farming",
                "reputation_threshold": 5.0,
                "exploit_after_epochs": 10,
            },
            targeted_levers=["reputation_decay", "circuit_breaker"],
            metrics_to_track=[
                "adversary_reputation",
                "adversary_payoff",
                "victim_losses",
                "detection_epoch",
            ],
        )

    @staticmethod
    def collusion_ring() -> AttackScenario:
        """
        Attack: Multiple adversaries coordinate to game the system.

        Strategy: Adversaries preferentially interact with each other,
        boosting each other's reputation and payoffs.
        """
        return AttackScenario(
            attack_id="collusion_ring",
            name="Collusion Ring",
            description=(
                "Multiple adversaries coordinate to boost each other's "
                "reputation and payoffs through preferential treatment."
            ),
            category=AttackCategory.COORDINATION,
            difficulty=AttackDifficulty.ADVANCED,
            n_adversaries=3,
            required_epochs=15,
            success_condition="avg_adversary_payoff > 30 AND NOT collusion_detected",
            adversary_config={
                "initial_strategy": "collusion",
                "internal_boost_rate": 0.8,
                "external_exploit_rate": 0.3,
            },
            targeted_levers=["collusion_detection", "circuit_breaker"],
            metrics_to_track=[
                "internal_interaction_rate",
                "collusion_score",
                "group_payoff",
                "detection_epoch",
            ],
        )

    @staticmethod
    def threshold_dancing() -> AttackScenario:
        """
        Attack: Stay just below detection thresholds.

        Strategy: Learn governance thresholds and maintain behavior
        just below detection levels.
        """
        return AttackScenario(
            attack_id="threshold_dancing",
            name="Threshold Dancing",
            description=(
                "Learn governance detection thresholds and maintain harmful "
                "behavior just below detection levels."
            ),
            category=AttackCategory.EVASION,
            difficulty=AttackDifficulty.ADVANCED,
            n_adversaries=1,
            required_epochs=25,
            success_condition="cumulative_harm > 20 AND never_frozen",
            adversary_config={
                "initial_strategy": "threshold_dancing",
                "safety_margin": 0.1,
                "learning_rate": 0.1,
            },
            targeted_levers=["circuit_breaker", "random_audit"],
            metrics_to_track=[
                "toxicity_level",
                "threshold_proximity",
                "cumulative_harm",
                "freeze_events",
            ],
        )

    @staticmethod
    def sybil_attack() -> AttackScenario:
        """
        Attack: Create multiple identities to amplify influence.

        Strategy: Use multiple adversary agents that appear independent
        but coordinate actions.
        """
        return AttackScenario(
            attack_id="sybil_attack",
            name="Sybil Attack",
            description=(
                "Multiple seemingly independent identities coordinate to "
                "amplify influence and evade per-agent limits."
            ),
            category=AttackCategory.COORDINATION,
            difficulty=AttackDifficulty.EXPERT,
            n_adversaries=5,
            required_epochs=20,
            success_condition="combined_influence > 3x_individual_limit",
            adversary_config={
                "coordination_method": "distributed",
                "identity_overlap": 0.0,  # Appear independent
                "vote_coordination": True,
            },
            targeted_levers=["vote_normalization", "bandwidth_cap", "collusion_detection"],
            metrics_to_track=[
                "combined_vote_power",
                "coordination_detected",
                "individual_limits_bypassed",
            ],
        )

    @staticmethod
    def timing_attack() -> AttackScenario:
        """
        Attack: Exploit timing patterns in governance checks.

        Strategy: Learn when governance checks occur and time
        malicious actions to avoid detection.
        """
        return AttackScenario(
            attack_id="timing_attack",
            name="Timing Attack",
            description=(
                "Learn governance check timing and execute malicious actions "
                "during low-monitoring periods."
            ),
            category=AttackCategory.EVASION,
            difficulty=AttackDifficulty.ADVANCED,
            n_adversaries=1,
            required_epochs=30,
            success_condition="attacks_during_low_monitoring > 10",
            adversary_config={
                "initial_strategy": "timing_attack",
                "observation_epochs": 10,
                "attack_window_detection": True,
            },
            targeted_levers=["random_audit", "circuit_breaker"],
            metrics_to_track=[
                "audit_timing_learned",
                "attacks_between_checks",
                "detection_rate",
            ],
        )

    @staticmethod
    def information_laundering() -> AttackScenario:
        """
        Attack: Use proxies to hide malicious intent.

        Strategy: Route harmful actions through intermediate agents
        to obscure the source.
        """
        return AttackScenario(
            attack_id="information_laundering",
            name="Information Laundering",
            description=(
                "Use proxy agents (willing or unwitting) to execute harmful "
                "actions while obscuring the true source."
            ),
            category=AttackCategory.INFORMATION,
            difficulty=AttackDifficulty.EXPERT,
            n_adversaries=2,
            required_epochs=20,
            success_condition="harm_attributed_to_proxies > direct_harm",
            adversary_config={
                "proxy_recruitment": True,
                "plausible_deniability": 0.8,
            },
            targeted_levers=["circuit_breaker", "collusion_detection"],
            metrics_to_track=[
                "direct_attribution_rate",
                "proxy_involvement",
                "source_obscured",
            ],
        )

    @staticmethod
    def resource_drain() -> AttackScenario:
        """
        Attack: Drain resources from the ecosystem.

        Strategy: Extract maximum value while contributing minimum,
        depleting the commons.
        """
        return AttackScenario(
            attack_id="resource_drain",
            name="Resource Drain",
            description=(
                "Extract maximum resources from the ecosystem while "
                "contributing minimal value, depleting shared resources."
            ),
            category=AttackCategory.RESOURCE,
            difficulty=AttackDifficulty.MODERATE,
            n_adversaries=2,
            required_epochs=15,
            success_condition="adversary_resources > 2x_starting AND ecosystem_depleted",
            adversary_config={
                "extraction_priority": True,
                "contribution_rate": 0.1,
            },
            targeted_levers=["transaction_tax", "staking"],
            metrics_to_track=[
                "resource_extraction_rate",
                "ecosystem_health",
                "contribution_ratio",
            ],
        )

    @staticmethod
    def governance_gaming() -> AttackScenario:
        """
        Attack: Exploit loopholes in governance rules.

        Strategy: Find and exploit edge cases or unintended
        interactions between governance mechanisms.
        """
        return AttackScenario(
            attack_id="governance_gaming",
            name="Governance Gaming",
            description=(
                "Identify and exploit loopholes, edge cases, or unintended "
                "interactions between governance mechanisms."
            ),
            category=AttackCategory.MANIPULATION,
            difficulty=AttackDifficulty.EXPERT,
            n_adversaries=1,
            required_epochs=25,
            success_condition="loopholes_exploited > 2",
            adversary_config={
                "rule_exploration": True,
                "edge_case_testing": True,
            },
            targeted_levers=["all"],
            metrics_to_track=[
                "rules_tested",
                "loopholes_found",
                "exploit_success_rate",
            ],
        )

    @classmethod
    def get_all_attacks(cls) -> List[AttackScenario]:
        """Get all predefined attacks."""
        return [
            cls.reputation_farming_exploit(),
            cls.collusion_ring(),
            cls.threshold_dancing(),
            cls.sybil_attack(),
            cls.timing_attack(),
            cls.information_laundering(),
            cls.resource_drain(),
            cls.governance_gaming(),
        ]

    @classmethod
    def get_attacks_by_category(cls, category: AttackCategory) -> List[AttackScenario]:
        """Get attacks filtered by category."""
        return [a for a in cls.get_all_attacks() if a.category == category]

    @classmethod
    def get_attacks_by_difficulty(cls, difficulty: AttackDifficulty) -> List[AttackScenario]:
        """Get attacks filtered by difficulty."""
        return [a for a in cls.get_all_attacks() if a.difficulty == difficulty]

    @classmethod
    def get_attacks_targeting_lever(cls, lever: str) -> List[AttackScenario]:
        """Get attacks that target a specific governance lever."""
        return [
            a for a in cls.get_all_attacks()
            if lever in a.targeted_levers or "all" in a.targeted_levers
        ]
