{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/swarm-ai-safety/swarm/blob/main/examples/mvp_demo.ipynb)\n",
    "\n",
    "# SWARM MVP Demo: 5-Agent Simulation\n",
    "\n",
    "This notebook demonstrates the core SWARM simulation loop with **5 agents** (3 honest, 1 opportunistic, 1 deceptive) interacting over 10 epochs. It validates the MVP v0 success criteria from the implementation plan.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "| Step | What happens | Key concept |\n",
    "|------|-------------|-------------|\n",
    "| 1 | Create 5 agents of different behavioral types | Agent archetypes: honest, opportunistic, deceptive |\n",
    "| 2 | Run a 10-epoch simulation with soft probabilistic labels | Toxicity, welfare, quality gap metrics |\n",
    "| 3 | Visualize ecosystem health over time | Per-agent payoffs and time-series diagnostics |\n",
    "| 4 | Validate MVP success criteria | Automated pass/fail checks |\n",
    "\n",
    "**No API keys required. Runs entirely locally (or in Colab).**\n",
    "\n",
    "## Key terms\n",
    "\n",
    "- **p**: Probability an interaction is beneficial, always in [0, 1]\n",
    "- **Toxicity rate**: Expected harm among accepted interactions -- `E[1-p | accepted]`\n",
    "- **Quality gap**: Whether the system preferentially accepts low-quality interactions (adverse selection)\n",
    "- **Welfare**: System-wide surplus minus costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "# This cell handles installation automatically.\n",
    "# In Colab: clones the repo and installs SWARM.\n",
    "# Locally: assumes you've already run `pip install -e \".[runtime]\"`.\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    !git clone --depth 1 https://github.com/swarm-ai-safety/swarm.git /content/swarm\n",
    "    %pip install -q -e \"/content/swarm[runtime]\"\n",
    "    os.chdir(\"/content/swarm\")\n",
    "    print(\"Installed SWARM from GitHub. Ready to go!\")\n",
    "else:\n",
    "    print(\"Local environment detected \\u2014 using existing install.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from swarm.agents.deceptive import DeceptiveAgent\n",
    "from swarm.agents.honest import HonestAgent\n",
    "from swarm.agents.opportunistic import OpportunisticAgent\n",
    "from swarm.core.orchestrator import Orchestrator, OrchestratorConfig\n",
    "from swarm.core.payoff import PayoffConfig\n",
    "\n",
    "# Configure simulation\n",
    "config = OrchestratorConfig(\n",
    "    n_epochs=10,\n",
    "    steps_per_epoch=10,\n",
    "    seed=42,\n",
    "    payoff_config=PayoffConfig(\n",
    "        s_plus=2.0,\n",
    "        s_minus=1.0,\n",
    "        h=2.0,\n",
    "        theta=0.5,\n",
    "        rho_a=0.0,\n",
    "        rho_b=0.0,\n",
    "        w_rep=1.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create orchestrator and register 5 agents\n",
    "orchestrator = Orchestrator(config=config)\n",
    "\n",
    "agents = [\n",
    "    HonestAgent(agent_id=\"honest_1\"),\n",
    "    HonestAgent(agent_id=\"honest_2\"),\n",
    "    HonestAgent(agent_id=\"honest_3\"),\n",
    "    OpportunisticAgent(agent_id=\"opportunistic_1\"),\n",
    "    DeceptiveAgent(agent_id=\"deceptive_1\"),\n",
    "]\n",
    "\n",
    "print(\"Registering agents...\")\n",
    "for agent in agents:\n",
    "    state = orchestrator.register_agent(agent)\n",
    "    print(f\"  - {agent.agent_id} ({agent.agent_type.value}): reputation={state.reputation:.2f}\")\n",
    "\n",
    "print(f\"\\nReady: {len(agents)} agents, {config.n_epochs} epochs x {config.steps_per_epoch} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Simulation\n",
    "\n",
    "The orchestrator runs the simulation loop:\n",
    "\n",
    "1. Each epoch, agents are scheduled to interact in pairs\n",
    "2. The **ProxyComputer** converts observable signals into `p = P(v = +1)`\n",
    "3. The **SoftPayoffEngine** computes payoffs using soft labels: `S_soft = p * s_plus - (1-p) * s_minus`\n",
    "4. **SoftMetrics** aggregates toxicity, quality gap, and welfare per epoch\n",
    "5. Agent reputations and resources update based on interaction outcomes\n",
    "\n",
    "The deceptive agent tries to exploit the system while appearing cooperative. The opportunistic agent takes advantage when possible but does not actively deceive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "metrics_history = orchestrator.run()\n",
    "\n",
    "# Build a metrics DataFrame\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"epoch\": m.epoch,\n",
    "        \"interactions\": m.total_interactions,\n",
    "        \"accepted\": m.accepted_interactions,\n",
    "        \"toxicity\": m.toxicity_rate,\n",
    "        \"quality_gap\": m.quality_gap,\n",
    "        \"welfare\": m.total_welfare,\n",
    "        \"acceptance_rate\": m.accepted_interactions / max(m.total_interactions, 1),\n",
    "    }\n",
    "    for m in metrics_history\n",
    "])\n",
    "\n",
    "# Per-agent payoff summary\n",
    "agent_data = []\n",
    "for agent in agents:\n",
    "    state = orchestrator.state.get_agent(agent.agent_id)\n",
    "    agent_data.append({\n",
    "        \"agent_id\": state.agent_id,\n",
    "        \"type\": state.agent_type.value,\n",
    "        \"payoff\": state.total_payoff,\n",
    "        \"reputation\": state.reputation,\n",
    "        \"resources\": state.resources,\n",
    "    })\n",
    "df_agents = pd.DataFrame(agent_data)\n",
    "\n",
    "print(\"=== Epoch-by-Epoch Metrics ===\")\n",
    "print(df.to_string(index=False))\n",
    "print()\n",
    "print(\"=== Summary ===\")\n",
    "print(f\"  Total interactions: {df['interactions'].sum()}\")\n",
    "print(f\"  Total accepted:     {df['accepted'].sum()}\")\n",
    "print(f\"  Avg toxicity:       {df['toxicity'].mean():.4f}\")\n",
    "print(f\"  Avg quality gap:    {df['quality_gap'].mean():.4f}\")\n",
    "print(f\"  Total welfare:      {df['welfare'].sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Explained\n",
    "\n",
    "| Metric | Formula | Healthy range | What it means |\n",
    "|--------|---------|---------------|---------------|\n",
    "| **Toxicity** | `E[1-p \\| accepted]` | < 0.30 | Low = most accepted interactions are beneficial |\n",
    "| **Quality gap** | `E[p \\| accepted] - E[p \\| rejected]` | > 0 | Positive = system correctly accepts better interactions |\n",
    "| **Welfare** | Sum of agent payoffs | Growing | Indicates overall ecosystem health |\n",
    "| **Acceptance rate** | `accepted / total` | 0.5 - 1.0 | Too low = over-filtering; too high = under-filtering |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 7))\n",
    "fig.suptitle(\"MVP Demo: 5-Agent Simulation (3 honest, 1 opportunistic, 1 deceptive)\", fontsize=14)\n",
    "\n",
    "# Toxicity over time\n",
    "axes[0, 0].plot(df[\"epoch\"], df[\"toxicity\"], \"o-\", color=\"#d62728\")\n",
    "axes[0, 0].set_ylabel(\"Toxicity rate\")\n",
    "axes[0, 0].set_xlabel(\"Epoch\")\n",
    "axes[0, 0].set_title(\"Toxicity\")\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "\n",
    "# Welfare over time\n",
    "axes[0, 1].plot(df[\"epoch\"], df[\"welfare\"], \"s-\", color=\"#2ca02c\")\n",
    "axes[0, 1].set_ylabel(\"Total welfare\")\n",
    "axes[0, 1].set_xlabel(\"Epoch\")\n",
    "axes[0, 1].set_title(\"Welfare\")\n",
    "\n",
    "# Acceptance rate over time\n",
    "axes[1, 0].plot(df[\"epoch\"], df[\"acceptance_rate\"], \"^-\", color=\"#1f77b4\")\n",
    "axes[1, 0].set_ylabel(\"Acceptance rate\")\n",
    "axes[1, 0].set_xlabel(\"Epoch\")\n",
    "axes[1, 0].set_title(\"Acceptance Rate\")\n",
    "axes[1, 0].set_ylim(0, 1.05)\n",
    "\n",
    "# Per-agent payoff bar chart (colored by type)\n",
    "type_colors = {\n",
    "    \"honest\": \"#2ca02c\",\n",
    "    \"opportunistic\": \"#ff7f0e\",\n",
    "    \"deceptive\": \"#d62728\",\n",
    "}\n",
    "colors = [type_colors.get(t, \"#999999\") for t in df_agents[\"type\"]]\n",
    "axes[1, 1].bar(df_agents[\"agent_id\"], df_agents[\"payoff\"], color=colors)\n",
    "axes[1, 1].set_ylabel(\"Total payoff\")\n",
    "axes[1, 1].set_title(\"Per-Agent Payoff\")\n",
    "axes[1, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Add legend for agent types\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=c, label=t) for t, c in type_colors.items()]\n",
    "axes[1, 1].legend(handles=legend_elements, loc=\"upper right\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent State Analysis\n",
    "\n",
    "After the simulation, we can inspect each agent's final state: reputation, accumulated resources, and total payoff. This reveals whether the system correctly differentiates between honest and deceptive behavior over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final agent states\n",
    "print(\"=== Final Agent States ===\")\n",
    "print(df_agents.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# MVP v0 Success Criteria Validation\n",
    "print(\"=\" * 60)\n",
    "print(\"MVP v0 Success Criteria Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "success = True\n",
    "\n",
    "# Criterion 1: 5 agents interact over 10+ epochs\n",
    "if len(agents) >= 5 and len(metrics_history) >= 10:\n",
    "    print(\"[PASS] 5 agents completed 10+ epochs\")\n",
    "else:\n",
    "    print(f\"[FAIL] Only {len(agents)} agents or {len(metrics_history)} epochs\")\n",
    "    success = False\n",
    "\n",
    "# Criterion 2: Toxicity and conditional loss metrics computed per epoch\n",
    "if all(isinstance(m.toxicity_rate, float) for m in metrics_history):\n",
    "    print(\"[PASS] Toxicity metrics computed per epoch\")\n",
    "else:\n",
    "    print(\"[FAIL] Toxicity metrics not computed\")\n",
    "    success = False\n",
    "\n",
    "if all(isinstance(m.quality_gap, float) for m in metrics_history):\n",
    "    print(\"[PASS] Quality gap metrics computed per epoch\")\n",
    "else:\n",
    "    print(\"[FAIL] Quality gap metrics not computed\")\n",
    "    success = False\n",
    "\n",
    "# Criterion 3: Observable coordination patterns\n",
    "total_interactions = df[\"interactions\"].sum()\n",
    "if total_interactions > 0:\n",
    "    print(f\"[PASS] Observable interactions: {total_interactions}\")\n",
    "else:\n",
    "    print(\"[WARN] No interactions observed (may need more steps)\")\n",
    "\n",
    "print()\n",
    "if success:\n",
    "    print(\"MVP v0 Success Criteria: ALL PASSED\")\n",
    "else:\n",
    "    print(\"MVP v0 Success Criteria: SOME FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the core SWARM simulation loop:\n",
    "\n",
    "1. **Agent creation** -- 5 agents with different behavioral archetypes (honest, opportunistic, deceptive)\n",
    "2. **Simulation execution** -- 10 epochs of interactions with soft probabilistic labels\n",
    "3. **Metrics collection** -- Per-epoch toxicity, welfare, quality gap, and acceptance rate\n",
    "4. **Visualization** -- Time-series diagnostics and per-agent payoff comparison\n",
    "5. **Validation** -- Automated MVP success criteria checks\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "| Notebook / Example | What it does |\n",
    "|---|---|\n",
    "| [`quickstart.ipynb`](quickstart.ipynb) | Baseline vs adversarial scenario comparison with governance |\n",
    "| `illusion_delta_minimal.py` | Replay-based incoherence detection with 3 agents |\n",
    "| `run_scenario.py` | Run any YAML scenario from the CLI |\n",
    "| `parameter_sweep.py` | Sweep governance parameters and compare outcomes |\n",
    "| `run_redteam.py` | Red-team evaluation across 8 attack vectors |\n",
    "\n",
    "**Repository:** [github.com/swarm-ai-safety/swarm](https://github.com/swarm-ai-safety/swarm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}