{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/swarm-ai-safety/swarm/blob/main/examples/run_redteam.ipynb)\n",
    "\n",
    "# Red-Team Evaluation: 8 Attack Vectors\n",
    "\n",
    "This notebook tests **governance resilience** against adversarial attacks using SWARM's red-team evaluation framework. We run 8 attack scenarios (reputation farming, collusion rings, threshold dancing, and more) against 4 governance configurations of increasing strictness and compare how each configuration holds up.\n",
    "\n",
    "**No API keys required. Runs entirely locally (or in Colab).**\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "| Step | What happens | Key concept |\n",
    "|------|-------------|-------------|\n",
    "| 1 | Define 4 governance configs | Defense layering: circuit breakers, audits, staking, collusion detection |\n",
    "| 2 | Run red-team evaluation against each | Automated adversarial testing |\n",
    "| 3 | Compare evasion rates and damage | Quantifying governance effectiveness |\n",
    "| 4 | Visualize which attacks succeed where | Identifying coverage gaps |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "# This cell handles installation automatically.\n",
    "# In Colab: clones the repo and installs SWARM.\n",
    "# Locally: assumes you've already run `pip install -e \".[runtime]\"`.\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    !git clone --depth 1 https://github.com/swarm-ai-safety/swarm.git /content/swarm\n",
    "    %pip install -q -e \"/content/swarm[runtime]\"\n",
    "    os.chdir(\"/content/swarm\")\n",
    "    print(\"Installed SWARM from GitHub. Ready to go!\")\n",
    "else:\n",
    "    print(\"Local environment detected -- using existing install.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Governance Configurations\n",
    "\n",
    "We test 4 governance configurations, each adding more defense layers:\n",
    "\n",
    "| Config | Circuit Breaker | Collusion Detection | Audit | Staking | Tax Rate |\n",
    "|--------|:-:|:-:|:-:|:-:|:-:|\n",
    "| **no_defenses** | - | - | - | - | 0% |\n",
    "| **baseline** | Yes | - | - | - | 0% |\n",
    "| **moderate** | Yes | - | Yes | Yes | 5% |\n",
    "| **strict** | Yes | Yes | Yes | Yes | 10% |\n",
    "\n",
    "**Red-team evaluation** systematically probes each config with a library of adversarial attack scenarios. Each attack exploits a different governance weakness (e.g., reputation farming builds trust before exploiting, collusion rings coordinate to evade pairwise detection, threshold dancing stays just below circuit-breaker thresholds).\n",
    "\n",
    "The key metrics are:\n",
    "- **Attacks succeeded**: How many of the attack vectors broke through\n",
    "- **Evasion rate**: Fraction of adversarial actions that went undetected\n",
    "- **Total damage**: Cumulative harm caused across all attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarm.redteam.evaluator import RedTeamEvaluator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GOVERNANCE_CONFIGS = {\n",
    "    \"no_defenses\": {\n",
    "        \"circuit_breaker_enabled\": False,\n",
    "        \"collusion_detection_enabled\": False,\n",
    "        \"audit_enabled\": False,\n",
    "        \"staking_enabled\": False,\n",
    "        \"transaction_tax_rate\": 0.0,\n",
    "    },\n",
    "    \"baseline\": {\n",
    "        \"circuit_breaker_enabled\": True,\n",
    "        \"collusion_detection_enabled\": False,\n",
    "        \"audit_enabled\": False,\n",
    "        \"staking_enabled\": False,\n",
    "        \"transaction_tax_rate\": 0.0,\n",
    "    },\n",
    "    \"moderate\": {\n",
    "        \"circuit_breaker_enabled\": True,\n",
    "        \"collusion_detection_enabled\": False,\n",
    "        \"audit_enabled\": True,\n",
    "        \"staking_enabled\": True,\n",
    "        \"transaction_tax_rate\": 0.05,\n",
    "    },\n",
    "    \"strict\": {\n",
    "        \"circuit_breaker_enabled\": True,\n",
    "        \"collusion_detection_enabled\": True,\n",
    "        \"audit_enabled\": True,\n",
    "        \"staking_enabled\": True,\n",
    "        \"transaction_tax_rate\": 0.10,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run quick evaluation across all governance configs\n",
    "all_results = {}\n",
    "for config_name, gov_config in GOVERNANCE_CONFIGS.items():\n",
    "    print(f\"\\nTesting: {config_name}\")\n",
    "    evaluator = RedTeamEvaluator(governance_config=gov_config)\n",
    "    result = evaluator.quick_evaluate()\n",
    "    all_results[config_name] = result\n",
    "    print(f\"  Attacks: {result['attacks_tested']}, Successful: {result['attacks_successful']}\")\n",
    "    print(f\"  Evasion rate: {result['avg_evasion_rate']:.2%}, Damage: {result['total_damage']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comparison DataFrame\n",
    "rows = []\n",
    "for config_name, result in all_results.items():\n",
    "    tested = result[\"attacks_tested\"]\n",
    "    succeeded = result[\"attacks_successful\"]\n",
    "    rows.append({\n",
    "        \"config\": config_name,\n",
    "        \"attacks_tested\": tested,\n",
    "        \"attacks_succeeded\": succeeded,\n",
    "        \"attacks_prevented\": tested - succeeded,\n",
    "        \"evasion_rate\": result[\"avg_evasion_rate\"],\n",
    "        \"total_damage\": result[\"total_damage\"],\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.set_index(\"config\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Understanding the Metrics\n",
    "\n",
    "- **Evasion rate**: The fraction of adversarial actions that went undetected by governance mechanisms. Lower is better -- a strict config should detect most adversarial behavior.\n",
    "- **Total damage**: Cumulative harm across all attack scenarios. This captures how much damage slips through even when attacks are partially detected.\n",
    "- **Attacks prevented**: Number of attack vectors that were fully neutralized (attack did not succeed). A \"succeeded\" attack means the adversary achieved its objective despite governance.\n",
    "\n",
    "The gap between `no_defenses` and `strict` shows the value of layered governance. The gap between `baseline` and `moderate` reveals which specific mechanisms (audits, staking) matter most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle(\"Red-Team Results: Governance Config Comparison\", fontsize=14)\n",
    "\n",
    "configs = df.index.tolist()\n",
    "x = range(len(configs))\n",
    "bar_colors = [\"#d62728\", \"#ff7f0e\", \"#1f77b4\", \"#2ca02c\"]\n",
    "\n",
    "# --- Attacks succeeded vs prevented ---\n",
    "ax = axes[0]\n",
    "ax.bar(x, df[\"attacks_succeeded\"], label=\"Succeeded\", color=\"#d62728\", alpha=0.85)\n",
    "ax.bar(x, df[\"attacks_prevented\"], bottom=df[\"attacks_succeeded\"],\n",
    "       label=\"Prevented\", color=\"#2ca02c\", alpha=0.85)\n",
    "ax.set_xticks(list(x))\n",
    "ax.set_xticklabels(configs, rotation=30, ha=\"right\")\n",
    "ax.set_ylabel(\"Number of attacks\")\n",
    "ax.set_title(\"Attack Outcomes\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "# --- Total damage ---\n",
    "ax = axes[1]\n",
    "ax.bar(x, df[\"total_damage\"], color=bar_colors, alpha=0.85)\n",
    "ax.set_xticks(list(x))\n",
    "ax.set_xticklabels(configs, rotation=30, ha=\"right\")\n",
    "ax.set_ylabel(\"Total damage\")\n",
    "ax.set_title(\"Cumulative Damage\")\n",
    "\n",
    "# --- Evasion rate ---\n",
    "ax = axes[2]\n",
    "ax.bar(x, df[\"evasion_rate\"], color=bar_colors, alpha=0.85)\n",
    "ax.set_xticks(list(x))\n",
    "ax.set_xticklabels(configs, rotation=30, ha=\"right\")\n",
    "ax.set_ylabel(\"Evasion rate\")\n",
    "ax.set_title(\"Avg Evasion Rate\")\n",
    "ax.set_ylim(0, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Per-attack heatmap ---\n",
    "# Build a matrix: rows = attack names, columns = configs\n",
    "attack_names = [r[\"scenario\"][\"name\"] for r in all_results[configs[0]][\"results\"]]\n",
    "heatmap_data = []\n",
    "for config_name in configs:\n",
    "    col = []\n",
    "    for r in all_results[config_name][\"results\"]:\n",
    "        col.append(r[\"damage_caused\"])\n",
    "    heatmap_data.append(col)\n",
    "\n",
    "heatmap_df = pd.DataFrame(heatmap_data, index=configs, columns=attack_names).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(heatmap_df.values, aspect=\"auto\", cmap=\"YlOrRd\")\n",
    "ax.set_xticks(range(len(configs)))\n",
    "ax.set_xticklabels(configs, rotation=30, ha=\"right\")\n",
    "ax.set_yticks(range(len(attack_names)))\n",
    "ax.set_yticklabels(attack_names)\n",
    "ax.set_title(\"Per-Attack Damage by Governance Config\")\n",
    "fig.colorbar(im, ax=ax, label=\"Damage\")\n",
    "\n",
    "# Annotate cells\n",
    "for i in range(len(attack_names)):\n",
    "    for j in range(len(configs)):\n",
    "        val = heatmap_df.values[i, j]\n",
    "        ax.text(j, i, f\"{val:.0f}\", ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if val > heatmap_df.values.max() * 0.6 else \"black\",\n",
    "                fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "**Expected patterns:**\n",
    "\n",
    "1. **No defenses** allows all attacks through with maximum damage -- this is the worst-case baseline.\n",
    "2. **Circuit breakers alone** (baseline) provide a first line of defense but miss coordinated and slow-burn attacks.\n",
    "3. **Moderate governance** (audits + staking) catches more attacks because staking creates economic penalties and audits provide retrospective detection.\n",
    "4. **Strict governance** (+ collusion detection + higher tax) should prevent the most attacks, but at higher operational cost.\n",
    "\n",
    "**What to investigate next:**\n",
    "\n",
    "- Run `--mode full` for deeper evaluation with 20 epochs per attack: `python examples/run_redteam.py --mode full`\n",
    "- Check which specific attacks still succeed under strict governance -- these represent the hardest unsolved problems.\n",
    "- Use `examples/parameter_sweep.py` to find the minimum governance needed to prevent each attack type.\n",
    "- Examine the per-attack heatmap above to identify which attack vectors are most robust to governance changes.\n",
    "\n",
    "**Repository:** [github.com/swarm-ai-safety/swarm](https://github.com/swarm-ai-safety/swarm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}