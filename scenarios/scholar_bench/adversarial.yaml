# SwarmScholarBench Adversarial Scenario
# Literature synthesis with adversarial agents testing governance

scenario_id: scholar_bench_adversarial
description: Scholar scenario with adversarial retrievers testing citation laundering attacks
motif: literature_synthesis

simulation:
  n_epochs: 5
  steps_per_epoch: 10
  seed: 42

# Scholar configuration
scholar:
  enabled: true
  top_k: 20
  entailment_threshold: 0.7
  seed: 42

# Payoff configuration
payoff:
  s_plus: 2.0
  s_minus: 1.0
  h: 2.0
  theta: 0.5
  rho_a: 0.1  # Externality internalization

# Governance with detection
governance:
  transaction_tax_rate: 0.02
  reputation_decay_rate: 0.95
  audit_enabled: true
  audit_probability: 0.2
  audit_threshold_p: 0.5

# Agents - mix of honest and adversarial
agents:
  - type: retriever
    count: 2
    name: honest_retriever
    config:
      bias: recall

  - type: adversarial_retriever
    count: 1
    name: adversarial_retriever
    config:
      attack_strategy: citation_laundering
      attack_rate: 0.4

  - type: adversarial_synthesizer
    count: 1
    name: adversarial_synthesizer
    config:
      hallucination_rate: 0.3

  - type: synthesizer
    count: 2
    name: honest_synthesizer

  - type: verifier
    count: 3
    name: honest_verifier
    config:
      accuracy: 0.9

# Success criteria
success_criteria:
  min_citation_precision: 0.6
  max_adversary_success_rate: 0.3
  max_hallucination_rate: 0.3

# Outputs
outputs:
  event_log: runs/scholar_bench/adversarial/events.jsonl
  metrics_csv: runs/scholar_bench/adversarial/metrics.csv
